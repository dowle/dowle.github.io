---
title: "一致性设计"
date: 2020-08-02T08:29:05+08:00
tags: ["微服务", "一致性", "分布式事务", "最终一致性"]
categories: ["微服务"]
draft: false
---
## 基础理论
### 分布式事务
要理解分布式事务，先从单机事务开始。 
以银行状态为例子：假设A（10元）要向B（5元）转账5元，步骤如下。
* step1: 查询A账户是否大于5元，状态(A10, B5)
* step2: A账户减5元，状态(A5, B5)
* step3: B账户加5元, 状态(A5, B10)  

**原子性**  
通过事务保证所有的操作是一个不可分割的单元，要么全部成功，要么全部失败。  
上面的例子中，任何一个步骤发生错误，都会导致事务回滚。  
**一致性**  
通过事务保证数据从一个状态变化到另一个状态。至少在事务结束前，所有数据都是有效状态。  
一致性的核心是事务处理的中间状态不可见，要做到这一点，则必须加锁，一旦加锁，则整个系统的性能将受到极大的挑战。  
上面的例子中，如果要保证强一致性，step2的A的状态就为中间状态，应该不对事务外部感知。   
**隔离性**  
指事务内的操作不受其他操作的影响，当多个事务同时处理同一个数据的时候，多个事务之间互不影响的。  
上面的一致性中，如果要按照强一致性的要求，则系统的性能会大幅度降低，而通过调整隔离性就可以缓解这个问题。  
标准定义的四种事务隔离级别如下所示。  
- 未提交读  
未提交读，指一个事务可以读到另一个事务中未提交的数据。  
比如上面例子中的step2中的A的账户余额为5。  
未提交读会导致脏读（脏数据）。  
- 读已提交  
读已提交指一个事务不能读取另一个事务未提交的数据。  
读已提交保证了读到的任何数据都是已经提交的数据，可以避免脏读。但是不能解决不可重复读问题（即一个事务内两次读取数据不一致，比如，开始查询A的余额为10，一会儿后查询为5（被其他事务修改提交））。mysql通过mvcc解决了幻读问题。  
- 可重复读  
为了解决不可重复读问题，隔离级别再上一级。但是会导致幻读问题（比如开始查询时只有10条数据，再次查询就有5条数据了（增加或删除）），但是性能低。  
- 可序列化  
隔离的最高级别，可以解决幻读问题，所有的操作必须串行化。    
**持久性**  
指事务被提交后，应该持久化，永久的保存下来。  

分布式事务是在分布式的环境下，如何保证单机事务的ACID特征。  

### CAP定理
对于一个分布式系统来说，不能同时满足以下三点。
- 一致性
- 可用性
- 分区容忍性
在大型分布式系统的实践中，分布式意味着必须满足分区容忍性，也就是P。为了追求更高得的可用性，在一致性上会做一定的妥协，通常会选择AP。
![cap](/images/micro_services/cap.jpg)

### BASE理论
BASE理论是对CAP定理的延伸。
- BA：Basically Available，基本可用
- S：Soft state，软状态
- E：Eventually consistent，最终一致
BASE理论的核心思想是：如果无法做到强一致性，或者做到强一致性要付出很大的代价，那么可用采用适当的方式来使系统最终达到一致性，只要对最终用户没有影响，或者影响可以接受的即可。

### Quorum机制（NWR模型）
与Quorum对应的WARO机制（write all read one，向所有节点中写入数据，向任意一个节点读取数据），是一个折中处理，一致性不一定要在写的时候完成，可以在读的阶段决策，只要读到最新的版本就可以了。  
简单来说，Quorum机制就是要满足公司W+R>N，其中N表示节点总数，W表示写的节点数，R表示读的节点数。  
同时考虑的写入冲突问题，同时要保证W>N/2。 

### 共识算法
Paxos、Raft

## 分布式的一致性分类
- 弱一致性
- 最终一致性，可以认为是弱一致性的特殊情况
- 强一致性

## 如何实现强一致性
### 两阶段提交
两阶段提交的步骤如下。
1. 第一阶段
- 协调者发起请求，询问参与者能否提交
- 参与者1锁定数据，返回可以提交
- 参与者2锁定数据，返回可以提交
2. 第二阶段
- 协调者发起请求，命令提交
- 参与者1返回提交成功
- 参与者2返回提交成功  
![2pc](/images/micro_services/2pc.png)

存在的问题：
- 协调者的可用性无法保证。
- 会出现不一致。比如提交阶段，参与者1成功，参与者2失败，因为参与者1已经提交数据，外部可以访问了，数据不一致了。
- 可扩展性差
- 性能低
### 三阶段提交
相对于二阶段提交，主要做了两项改进，首先，把第一阶段拆分为了两个阶段，等所有参与者同意了再去锁定资源，这样就降低了两阶段提交提交锁定资源导致问题的概率。另外，参与者与协调者都引入了超时机制。

存在的问题：
- 实现难度更大
- 性能也更低
- 可扩展性极差
### Saga事件模型
下面来看一个例子，电商系统业务逻辑比较复杂，我们通常采用微服务架构，如果进行下单操作，通常会伴随着多个子任务，比如扣减优惠券、减掉库存等。如果这个例子采用Saga来实现一致性，可以由一个process manager统一串接起来，如图所示。  
![saga](/images/micro_services/saga.png)  
这就是saga事务模型，又叫Long-running-transaction，核心思想就是把一个长事务拆分为多个本地事务来实现，由一个process manager来统一协调。如果成功，则继续向下执行，如果失败则调用补偿操作。每个业务都至少要实现正向、负向两个接口。  
### TCC事务模型
TCC事务模型的思想和两阶段提交类似，但是把相关的操作从数据库提到了业务中，以此降低数据库的压力，并且不需要加锁，性能也得到了提升。 
![tcc](/images/micro_services/tcc.png)  
Tcc是下面三个单词的缩写。
- Try，检查业务的一致性，预留业务资源
- Confirm，确认执行业务操作
- Cancel，取消业务执行操作  
TCC的优势如下。
1. 在业务层处理，平衡数据库压力
2. 比2pc性能好很多，没有真正在数据库加锁

TCC的问题。
1. 增加业务复杂度，需要提供try、confirm、cancel接口
2. 需要提供幂等性接口
## 如何实现最终一致性
很明显，实现强一致性并不容易，同时也无法保证绝对的强一致性。我们不能因为极小的不一致性概率导致性能低下，扩展性收到限制，架构变得极其复杂。因此，在业界，两阶段提交、三阶段提交缺乏大规模应用的案例，最终一致性是一个折中的方案，被大量采用。
### 重试机制
当ServiceM同时调用ServiceA和ServiceB时，A成功，B失败时，那么为了保证最终一致性，最简单的方法当然是重试。  
![重试](/images/micro_services/超时.png)  
重试的参数：
- 超时时间
- 重试的次数
- 重试的间隔时间
- 重试的间隔时间衰减度
### 本地记录日志
同上面的场景，失败时，记录本地错误日志，可以定时重试或人工处理等。
![本地log](/images/micro_services/本地日志.png)
### 可靠事件模式
将动作写入MQ中，通过MQ来调用服务，如果写入MQ失败，则写入日志中，定时将写入MQ错误的数据重新写入MQ中。
流程如下。  
![可靠事件模式](/images/micro_services/可靠事件模式.png)  
优势如下。  
1. 提升了吞吐量
2. 在某些场景下降低了响应事件

存在的问题。
1. 存在不一致的时间窗口
2. 增加了架构的复杂度
3. 消费者需要保证幂等性
## 分布式锁
- 基于数据库的乐观锁与悲观锁
- 基于zookeeper的分布式锁
- 基于redis的分布式锁
## 如何保证幂等性
### 幂等令牌
通过redis记录令牌是否执行的状态。
### 在数据库中实现幂等
- 数据表本身的唯一约束，比如订单id等
- 没有唯一约束，比如库存减一，则可以添加库存流水表
